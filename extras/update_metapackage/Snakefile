#############
### Setup ###
#############
# base environment: update_metapackage.yml
# update config.yaml
# run: snakemake --cores 64 --use-conda

import pandas as pd
import os

configfile: "config.yaml"
hmms_and_names = pd.read_csv("hmms_and_names", sep="\t").set_index("name", drop=False)
singlem_bin = "../../bin/singlem"
output_dir = config["output_dir"]
logs_dir = output_dir + "/logs"
genome_paths = [os.path.join(d, f) for d, _, fs in os.walk(config["gtdb_protein_faa_reps"]) for f in fs if f.endswith(".faa")]
genomes = ["/".join(g.split("/")[-2:]) for g in genome_paths]

if not "max_threads" in config: config["max_threads"] = 8

wildcard_constraints:
    genome = "(archaea|bacteria)/\w+.\d_protein.faa"

rule all:
    input:
        output_dir + "/metapackage/" + config["new_metapackage"]

####################
### HMM searches ###
####################
rule pfam_search:
    input:
        config["gtdb_protein_faa_reps"] + "/{genome}"
    output:
        output_dir + "/hmmsearch/pfam/{genome}.tsv"
    params:
        pfams = config["pfams"],
    threads: 1
    log:
        logs_dir + "/hmmsearch/pfam/{genome}.log"
    conda:
        "envs/hmm_tools.yml"
    shell:
        "pfam_search.pl "
        "-outfile {output} "
        "-cpu {threads} "
        "-fasta {input} "
        "-dir {params.pfams} "
        "&> {log}"

rule tigrfam_search:
    input:
        config["gtdb_protein_faa_reps"] + "/{genome}"
    output:
        output_dir + "/hmmsearch/tigrfam/{genome}.tsv"
    params:
        tigrfams = config["tigrfams"],
    threads: 1
    log:
        logs_dir + "/hmmsearch/tigrfam/{genome}.log"
    conda:
        "envs/hmm_tools.yml"
    shell:
        "hmmsearch "
        "-o /dev/null "
        "--tblout {output} "
        "--noali "
        "--notextw "
        "--cut_nc "
        "--cpu {threads} "
        "{params.tigrfams} "
        "{input} "
        "&> {log}"

rule get_matches_no_dup:
    input:
        pfam_search = output_dir + "/hmmsearch/pfam/{genome}.tsv",
        tigrfam_search = output_dir + "/hmmsearch/tigrfam/{genome}.tsv"
    output:
        output_dir + "/hmmsearch/matches/{genome}.fam"
    params:
        hmms_and_names = "hmms_and_names"
    log:
        logs_dir + "/hmmsearch/matches/{genome}_matching.log"
    conda:
        "envs/get_matches_no_dup.yml"
    shell:
        "python scripts/get_matches_no_dup.py "
        "--pfam-search {input.pfam_search} "
        "--tigrfam-search {input.tigrfam_search} "
        "--hmm-list {params.hmms_and_names} "
        "--output {output} "
        "&> {log}"

rule get_matching_seq_list:
    input:
        matches = output_dir + "/hmmsearch/matches/{genome}.fam"
    output:
        temp(output_dir + "/hmmsearch/matches/{genome}.tmp")
    shell:
        "cut -f1 {input} > {output}"

rule mfqe:
    input:
        fasta = config["gtdb_protein_faa_reps"] + "/{genome}",
        seqnames = output_dir + "/hmmsearch/matches/{genome}.tmp"
    output:
        output_dir + "/hmmsearch/matches/{genome}"
    log:
        logs_dir + "/hmmsearch/matches/{genome}_mfqe.log"
    conda:
        "../../singlem.yml"
    shell:
        "mfqe "
        "--input-fasta {input.fasta} "
        "--sequence-name-lists {input.seqnames} "
        "--output-fasta-files {output} "
        "--output-uncompressed "
        "&> {log}"

rule transpose_hmms_with_sequences:
    input:
        fasta = expand(output_dir + "/hmmsearch/matches/{genome}", genome=genomes),
        matches = expand(output_dir + "/hmmsearch/matches/{genome}.fam", genome=genomes),
    output:
        touch = output_dir + "/hmm_seq/done",
        dir = directory(output_dir + "/hmmseq/") # output is file for each spkg
    params:
        script = "scripts/transpose_hmms_with_sequences.py",
        gtdb_bac_tax = config["gtdb_bac_tax"],
        gtdb_arc_tax = config["gtdb_arc_tax"],
        hmms_and_names = "hmms_and_names"
    threads: 64
    conda:
        "envs/transpose_hmms_with_sequences.yml"
    shell:
        "parallel -j {threads} "
        "python {params.script} "
        "--input-fasta {{1}} "
        "--bacterial-taxonomy {params.gtdb_bac_tax} "
        "--archaeal-taxonomy {params.gtdb_arc_tax} "
        "--hmm-seq {{2}} "
        "--hmm-spkg {params.hmms_and_names} "
        "--output {output.dir} "
        "'&>' {logs_dir}/hmmsearch/matches/{{2/.}}_transpose.log "
        "::: {input.fasta} :::+ {input.matches} "
        "&& touch {output.touch}"

rule create_SingleM_packages:
    input:
        output_dir + "/hmm_seq/done"
    output:
        directory(output_dir + "/packages/{spkg}.spkg")
    params:
        singlem = singlem_bin,
        hmms_and_names = "hmms_and_names",
        uniprot_seq = config["uniprot_seq"],
        uniprot_tax = config["uniprot_tax"],
        spkg = config["metapackage"] + "/{spkg}.gpkg.spkg",
        spkg_seq = output_dir + "/hmmseq/{spkg}.faa",
        spkg_tax = output_dir + "/hmmseq/{spkg}_taxonomy.tsv",
        spkg_name = lambda wildcards: hmms_and_names.loc[wildcards.spkg, "name_without_number"]
    log:
        logs_dir + "/packages/{spkg}.log"
    conda:
        "../../singlem.yml"
    shell:
        "{params.singlem} regenerate "
        "--input_singlem_package {params.spkg} "
        "--input_sequences {params.spkg_seq} "
        "--input_taxonomy {params.spkg_tax} "
        "--euk_sequences {params.uniprot_seq} "
        "--euk_taxonomy {params.uniprot_tax} "
        "--output_singlem_package {output} "
        "--sequence_prefix {params.spkg_name}~ "
        "&> {log}"

rule create_SingleM_metapackage:
    input:
        expand(output_dir + "/packages/{spkg}.spkg", spkg = hmms_and_names.index)
    output:
        directory(output_dir + "/metapackage/" + config["new_metapackage"])
    params:
        singlem = singlem_bin
    threads: 8
    log:
        logs_dir + "/metapackage.log"
    conda:
        "../../singlem.yml"
    shell:
        "{params.singlem} metapackage "
        "--singlem-packages {input} "
        "--output-metapackage {output} "
        "--threads {threads} "
        "&> {log}"
