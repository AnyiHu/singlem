import os
import tempfile
import logging
import subprocess
import sqlite3
import glob
import json
import itertools
import sys

# Import masonite, pretty clunky
sys.path = [os.path.dirname(os.path.realpath(__file__))] + sys.path
import config.database
from masoniteorm.connections import ConnectionResolver
from masoniteorm.query import QueryBuilder

import nmslib
import numba
from numba.core import types
import Bio.Data.CodonTable

from .otu_table import OtuTableEntry, OtuTable


class SequenceDatabase:
    version = 4
    SQLITE_DB_NAME = 'otus.sqlite3'
    _marker_to_nucleotide_index_file = {}

    _CONTENTS_FILE_NAME = 'CONTENTS.json'

    VERSION_KEY = 'singlem_database_version'

    _REQUIRED_KEYS = {4: [VERSION_KEY]}

    def add_nucleotide_db(self, marker_name, db_path):
        self._marker_to_nucleotide_index_file[marker_name] = db_path

    def get_nucleotide_index(self, marker_name):
        if marker_name in self._marker_to_nucleotide_index_file:
            index_path = self._marker_to_nucleotide_index_file[marker_name]
            index = SequenceDatabase._nucleotide_nmslib_init()
            logging.debug("Loading index for {} from {}".format(marker_name, index_path))
            index.loadIndex(index_path, load_data=True)
            return index
        else:
            logging.warn("No nucleotide index DB found for %s" % marker_name)
            return None

    @staticmethod
    def _nucleotide_nmslib_init():
        return nmslib.init(space='bit_hamming', data_type=nmslib.DataType.OBJECT_AS_STRING, dtype=nmslib.DistType.INT, method='hnsw')

    def query_builder(self, check=False):
        return SequenceDatabase._query_builder(self.sqlite_file, check=check)

    @staticmethod
    def _query_builder(sqlite_db_path, check=False):
        '''setup config and return a query builder. If check==True, then make sure there the connection is alive, raising an exception otherwise'''
        if check:
            logging.debug("Connecting to DB {}".format(sqlite_db_path))        
            if not os.path.exists(sqlite_db_path):
                raise Exception("SQLite3 database does not appear to exist in the SingleM database - perhaps it is the wrong version?")

        DB = ConnectionResolver().set_connection_details({
            'default': 'singlem',
            'singlem': {
                'driver': 'sqlite',
                'database': sqlite_db_path,
                'prefix': '',
                'log_queries': False
            }
        })
        config.database.DB = DB

        qb = QueryBuilder(connection='singlem', connection_details=DB.get_connection_details())

        if check:
            try:
                len(qb.table('otus').limit(1).get())
                qb = QueryBuilder(connection='singlem', connection_details=DB.get_connection_details())
            except Exception as e:
                logging.error("Failure to extract any data from the otus table of the SQ Lite DB indicates this SingleM DB is either too old or is corrupt.")
                raise(e)

        return qb

    @staticmethod
    def acquire(path):
        db = SequenceDatabase()

        contents_path = os.path.join(
            path, SequenceDatabase._CONTENTS_FILE_NAME)
        if not os.path.exists(contents_path):
            logging.error("The SingleM database located at '{}' did not contain a contents file.".format(
                path) +
                          "This means that the DB is not at that location, is corrupt, or was generated by SingleM version 0.11.0 or older. So unfortunately the DB could not be loaded.")
            raise Exception("Failed to find contents file in SingleM DB {}".format(
                contents_path))
        with open(contents_path) as f:
            db._contents_hash = json.load(f)

        found_version = db._contents_hash[SequenceDatabase.VERSION_KEY]
        logging.debug("Loading version {} SingleM database: {}".format(
            found_version, path))
        if found_version == 4:
            for key in SequenceDatabase._REQUIRED_KEYS[found_version]:
                if key not in db._contents_hash:
                    raise Exception(
                        "Unexpectedly did not find required key {} in SingleM database contents file: {}".format(
                            key, path))
        else:
            raise Exception("Unexpected SingleM DB version found: {}".format(found_version))

        db.sqlite_file = os.path.join(path, SequenceDatabase.SQLITE_DB_NAME)

        nucleotide_index_files = glob.glob("%s/nucleotide_indices/*.nmslib_index" % path)
        logging.debug("Found nucleotide_index_files: %s" % ", ".join(nucleotide_index_files))
        if len(nucleotide_index_files) == 0: raise Exception("No nucleotide_index_files found in DB")
        for g in nucleotide_index_files:
            marker = os.path.basename(g).replace('.nmslib_index','')
            db.add_nucleotide_db(marker, g)
        return db

    @staticmethod
    def _grouper(iterable, n):
        args = [iter(iterable)] * n
        return itertools.zip_longest(*args, fillvalue=None)

    @staticmethod
    def create_from_otu_table(db_path, otu_table_collection, pregenerated_sqlite3_db=None):
        if pregenerated_sqlite3_db:
            logging.info("Re-using previous SQLite database {}".format(pregenerated_sqlite3_db))
            sqlite_db_path = pregenerated_sqlite3_db

            marker_list = set()
            for row in SequenceDatabase._query_builder(sqlite_db_path).table('otus').select_raw("distinct(marker) as marker").get():
                marker_list.add(row['marker'])
            logging.info("Found {} markers e.g. {}".format(len(marker_list), list(marker_list)[0]))

        else:
            # ensure db does not already exist
            if os.path.exists(db_path):
                raise Exception("Cowardly refusing to overwrite already-existing database path '%s'" % db_path)
            logging.info("Creating SingleM database at {}".format(db_path))
            os.makedirs(db_path)

            # Create contents file
            contents_file_path = os.path.join(db_path, SequenceDatabase._CONTENTS_FILE_NAME)
            with open(contents_file_path, 'w') as f:
                json.dump({
                    SequenceDatabase.VERSION_KEY: 4,
                }, f)

            # setup sqlite DB
            sqlite_db_path = os.path.join(db_path, SequenceDatabase.SQLITE_DB_NAME)
            logging.debug("Connecting to db %s" % sqlite_db_path)
            db = sqlite3.connect(sqlite_db_path)
            c = db.cursor()
            c.execute("CREATE TABLE otus (id INTEGER PRIMARY KEY AUTOINCREMENT,"
                    " marker text, sample_name text,"
                    " sequence text, num_hits int, coverage float, taxonomy text)")
            db.commit()

            logging.info("Creating database table with all OTU observations ..")
            chunksize = 10000 # Run in chunks for sqlite insert performance.
            for chunk in SequenceDatabase._grouper(otu_table_collection, chunksize):
                chunk_list = []
                for entry in chunk:
                    if entry is not None: # Is None when padded in last chunk.
                        chunk_list.append((entry.marker, entry.sample_name, entry.sequence, entry.count,
                            entry.coverage, entry.taxonomy))

                c.executemany("INSERT INTO otus(marker, sample_name, sequence, num_hits, "
                            "coverage, taxonomy) VALUES(?,?,?,?,?,?)",
                            chunk_list)

            logging.info("Creating SQLite indices ..")
            c.execute("CREATE UNIQUE INDEX otu_id on otus (id)")
            c.execute("CREATE INDEX otu_sequence on otus (sequence)")
            c.execute("CREATE INDEX otu_sample_name on otus (sample_name)")
            c.execute("CREATE INDEX otu_marker on otus (marker)")
            db.commit()

            logging.info("Creating markers table ..")
            c.execute("CREATE TABLE markers ("
                "id INTEGER PRIMARY KEY AUTOINCREMENT,"
                "marker text)")
            c.execute("INSERT INTO markers(marker) SELECT DISTINCT(marker) from otus ORDER BY marker")
            db.commit()
            c.execute("CREATE INDEX markers_marker on markers (marker)")
            db.commit()

            logging.info("Adding marker_id column to otus ..")
            c.execute('ALTER TABLE otus ADD COLUMN marker_id int')
            c.execute('UPDATE otus SET marker_id = daily.id FROM (SELECT id, marker from markers) AS daily WHERE otus.marker = daily.marker')
            db.commit()
            c.execute("DROP INDEX otu_marker")
            c.execute("ALTER table otus DROP COLUMN marker")
            db.commit()
            c.execute("CREATE INDEX otu_marker_id on otus (marker_id)")
            db.commit()

            logging.info("Creating nucleotide sequences table ..")
            c.execute("CREATE TABLE nucleotides ("
                "id INTEGER PRIMARY KEY AUTOINCREMENT,"
                "marker_id int,"
                "sequence text)")
            db.commit()
            c.execute("INSERT INTO nucleotides(marker_id, sequence) SELECT marker_id, sequence from otus GROUP BY marker_id, sequence")
            db.commit()
            c.execute("CREATE INDEX nucleotides_marker_id on nucleotides (marker_id)")
            c.execute("CREATE INDEX nucleotides_sequence on nucleotides (sequence)")
            db.commit()
            logging.info("Creating nucleotides foreign key in otus table ..")
            # Doing this takes way long, so instead we create a new table to replace otus
            # c.execute('ALTER TABLE otus ADD COLUMN nucleotides_id int')
            # c.execute('UPDATE otus SET nucleotides_id = daily.id FROM (SELECT id, marker_id, sequence from nucleotides) AS daily WHERE otus.marker_id = daily.marker_id and otus.sequence = daily.sequence')
            # 
            c.execute('ALTER TABLE otus RENAME to otus_previous')
            c.execute("CREATE TABLE otus (id INTEGER PRIMARY KEY AUTOINCREMENT,"
                    " marker_id int, sample_name text,"
                    " nucleotides_id, num_hits int, coverage float, taxonomy text)")
            c.execute("INSERT INTO otus(marker_id, sample_name, num_hits, coverage, taxonomy, nucleotides_id) "
                "SELECT nucleotides.marker_id, sample_name, num_hits, coverage, taxonomy, nucleotides.id "
                "FROM otus_previous JOIN nucleotides ON otus_previous.sequence = nucleotides.sequence AND otus_previous.marker_id = nucleotides.marker_id")
            db.commit()
            c.execute("DROP TABLE otus_previous")
            db.commit()
            c.execute("CREATE INDEX otu_sample_name on otus (sample_name)")
            c.execute("CREATE INDEX otu_marker_id on otus (marker_id)")
            c.execute("CREATE INDEX otu_nucleotide_id on otus (nucleotides_id)")
            db.commit()
            # TODO? Use ROW_NUMBER() with PARTITION to make sequential index for each marker? Only needed for Annoy? For proteins too?
            # https://www.sqlitetutorial.net/sqlite-window-functions/sqlite-row_number/

            logging.info("Creating protein sequences table ..")
            c.execute("CREATE TABLE proteins ("
                "id INTEGER PRIMARY KEY AUTOINCREMENT,"
                "marker_id int,"
                "nucleotide_id int,"
                "sequence text)")
            chunksize = 10000 # Run in chunks for sqlite insert performance.
            for chunk in SequenceDatabase._grouper(
                SequenceDatabase._query_builder(sqlite_db_path).table('nucleotides').select('id, marker_id, sequence').get(),
                chunksize):

                chunk_list = []
                for entry in chunk:
                    if entry is not None: # Is None when padded in last chunk.
                        chunk_list.append((entry['marker_id'], entry['id'], nucleotides_to_protein(entry['sequence'])))

                c.executemany("INSERT INTO proteins(marker_id, nucleotide_id, sequence) VALUES(?,?,?)",
                            chunk_list)
            db.commit()
            c.execute("CREATE INDEX proteins_marker_id on proteins (marker_id)")
            c.execute("CREATE INDEX proteins_nucleotide_id on proteins (nucleotide_id)")
            db.commit()
            
            

        # Create nucleotide index files
        logging.info("Creating nucleotide sequence indices ..")
        nucleotide_db_dir = os.path.join(db_path, 'nucleotide_indices')
        os.makedirs(nucleotide_db_dir)
        
        for marker_row in SequenceDatabase._query_builder(sqlite_db_path).table('markers').get():
            nucleotide_index = SequenceDatabase._nucleotide_nmslib_init()

            marker_name = marker_row['marker']
            logging.info("Tabulating unique nucleotide sequences for {}..".format(marker_name))
            count = 0

            for row in SequenceDatabase._query_builder(sqlite_db_path).table('nucleotides').select('sequence').select('id').where('marker_id', marker_row['id']).get():
                # logging.debug("Adding sequence with ID {}: {}".format(row['id'], row['sequence']))
                nucleotide_index.addDataPoint(row['id'], nucleotides_to_binary(row['sequence']))
                count += 1

            # TODO: Tweak index creation parameters?
            logging.info("Creating binary nucleotide index from {} unique sequences ..".format(count))
            nucleotide_index.createIndex()

            logging.info("Writing index to disk ..")
            nucleotide_db_path = os.path.join(nucleotide_db_dir, "%s.nmslib_index" % marker_name)
            nucleotide_index.saveIndex(nucleotide_db_path, save_data=True)
            logging.info("Finished writing index to disk")


        logging.info("Creating protein sequence indices ..")
        protein_db_dir = os.path.join(db_path, 'protein_indices')
        os.makedirs(protein_db_dir)
        for marker_row in SequenceDatabase._query_builder(sqlite_db_path).table('markers').get():
            protein_index = SequenceDatabase._nucleotide_nmslib_init()

            marker_name = marker_row['marker']
            logging.info("Tabulating unique protein sequences for {}..".format(marker_name))
            count = 0

            for row in SequenceDatabase._query_builder(sqlite_db_path).table('proteins').select('sequence').select_raw('min(id) as id').group_by('sequence').where('marker_id', marker_row['id']).get():
                # logging.debug("Adding sequence with ID {}: {}".format(row['id'], row['sequence']))
                protein_index.addDataPoint(row['id'], protein_to_binary(row['sequence']))
                count += 1

            # TODO: Tweak index creation parameters?
            logging.info("Creating binary protein index from {} unique sequences ..".format(count))
            protein_index.createIndex()

            logging.info("Writing index to disk ..")
            protein_db_path = os.path.join(protein_db_dir, "%s.nmslib_index" % marker_name)
            protein_index.saveIndex(protein_db_path, save_data=True)
            logging.info("Finished writing index to disk")

        logging.info("Finished singlem DB creation")
    
    @staticmethod
    def dump(db_path):
        """Dump the DB contents to STDOUT, requiring only that the DB is a version that
        has an otus table in sqlite3 form (i.e. version 2 at least).

        """
        sqlite_db_path = os.path.join(db_path, SequenceDatabase.SQLITE_DB_NAME)
        
        print("\t".join(OtuTable.DEFAULT_OUTPUT_FIELDS))
        for chunk in SequenceDatabase._query_builder(sqlite_db_path).table('otus').chunk(1000):
            for entry in chunk:
                otu = OtuTableEntry()
                otu.marker = entry['marker']
                otu.sample_name = entry['sample_name']
                otu.sequence = entry['sequence']
                otu.count = entry['num_hits']
                otu.coverage = entry['coverage']
                otu.taxonomy = entry['taxonomy']
                print(str(otu))

@numba.njit()
def _base_to_binary(x):
    if x == 'A':
        return '1 0 0 0 0'
    elif x == 'T':
        return '0 1 0 0 0'
    elif x == 'C':
        return '0 0 1 0 0'
    elif x == 'G':
        return '0 0 0 1 0'
    else:
        return '0 0 0 0 1'
    
@numba.njit()
def nucleotides_to_binary(seq):
    return ' '.join([_base_to_binary(b) for b in seq])

@numba.njit()
def _aa_to_binary(x):
    aas = ['W',
        'H',
        'Q',
        'M',
        'K',
        'G',
        'A',
        'I',
        'F',
        'S',
        'L',
        'Y',
        'T',
        'D',
        'E',
        'R',
        'P',
        'V',
        'N',
        'C',

        '-',
        'X']
    return ' '.join(['1' if aa == x else '0' for aa in aas])

@numba.njit()
def protein_to_binary(seq):
    return ' '.join([_aa_to_binary(b) for b in seq])

# @numba.njit() # would like to do this, but better to move to lists not dict for codon table
def nucleotides_to_protein(seq):
    aas = []
    codon_table=Bio.Data.CodonTable.standard_dna_table.forward_table
    for i in range(0, len(seq), 3):
        codon = seq[i:(i+3)]
        if codon == '---':
            aas.append('-')
        elif codon in codon_table:
            aas.append(codon_table[codon])
        else:
            aas.append('X')
    return ''.join(aas)